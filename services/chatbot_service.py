"""
ğŸ¯ ì±—ë´‡ ì„œë¹„ìŠ¤ - í•™ìƒ êµ¬í˜„ íŒŒì¼

ì´ íŒŒì¼ì€ ì±—ë´‡ì˜ í•µì‹¬ AI ë¡œì§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
ì•„ë˜ ì•„í‚¤í…ì²˜ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ì ‘ ì„¤ê³„í•˜ê³  êµ¬í˜„í•˜ì„¸ìš”.

ğŸ“ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. ì´ˆê¸°í™” ë‹¨ê³„ (ChatbotService.__init__)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - OpenAI Client ìƒì„±                                    â”‚
â”‚  - ChromaDB ì—°ê²° (ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤)                       â”‚
â”‚  - LangChain Memory ì´ˆê¸°í™” (ëŒ€í™” ê¸°ë¡ ê´€ë¦¬)               â”‚
â”‚  - Config íŒŒì¼ ë¡œë“œ                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. RAG íŒŒì´í”„ë¼ì¸ (generate_response ë‚´ë¶€)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  ì‚¬ìš©ì ì§ˆë¬¸ "í•™ì‹ ì¶”ì²œí•´ì¤˜"                              â”‚
â”‚       â†“                                                  â”‚
â”‚  [_create_embedding()]                                   â”‚
â”‚       â†“                                                  â”‚
â”‚  ì§ˆë¬¸ ë²¡í„°: [0.12, -0.34, ..., 0.78]  (3072ì°¨ì›)        â”‚
â”‚       â†“                                                  â”‚
â”‚  [_search_similar()]  â† ChromaDB ê²€ìƒ‰                    â”‚
â”‚       â†“                                                  â”‚
â”‚  ê²€ìƒ‰ ê²°ê³¼: "í•™ì‹ì€ ê³¤ìê°€ê°€ ë§›ìˆì–´" (ìœ ì‚¬ë„: 0.87)        â”‚
â”‚       â†“                                                  â”‚
â”‚  [_build_prompt()]                                       â”‚
â”‚       â†“                                                  â”‚
â”‚  ìµœì¢… í”„ë¡¬í”„íŠ¸ = ì‹œìŠ¤í…œ ì„¤ì • + RAG ì»¨í…ìŠ¤íŠ¸ + ì§ˆë¬¸        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. LLM ì‘ë‹µ ìƒì„±                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  OpenAI GPT-4 API í˜¸ì¶œ                                   â”‚
â”‚       â†“                                                  â”‚
â”‚  "í•™ì‹ì€ ê³¤ìê°€ì—ì„œ ë¨¹ëŠ” ê²Œ ì œì¼ ì¢‹ì•„! ëˆê¹ŒìŠ¤ê°€ ì¸ê¸°ì•¼"    â”‚
â”‚       â†“                                                  â”‚
â”‚  [ì„ íƒ: ì´ë¯¸ì§€ ê²€ìƒ‰]                                      â”‚
â”‚       â†“                                                  â”‚
â”‚  ì‘ë‹µ ë°˜í™˜: {reply: "...", image: "..."}                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. ë©”ëª¨ë¦¬ ì €ì¥ (LangChain Memory)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ëŒ€í™” ê¸°ë¡ì— ì§ˆë¬¸-ì‘ë‹µ ì €ì¥                               â”‚
â”‚  ë‹¤ìŒ ëŒ€í™”ì—ì„œ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


ğŸ’¡ í•µì‹¬ êµ¬í˜„ ê³¼ì œ:

1. **Embedding ìƒì„±**
   - OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
   - ëª¨ë¸: text-embedding-3-large (3072ì°¨ì›)

2. **RAG ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜** â­ ê°€ì¥ ì¤‘ìš”!
   - ChromaDBì—ì„œ ìœ ì‚¬ ë²¡í„° ê²€ìƒ‰
   - ìœ ì‚¬ë„ ê³„ì‚°: similarity = 1 / (1 + distance)
   - threshold ì´ìƒì¸ ë¬¸ì„œë§Œ ì„ íƒ

3. **LLM í”„ë¡¬í”„íŠ¸ ì„¤ê³„**
   - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìºë¦­í„° ì„¤ì •)
   - RAG ì»¨í…ìŠ¤íŠ¸ í†µí•©
   - ëŒ€í™” ê¸°ë¡ í¬í•¨

4. **ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬**
   - LangChainì˜ ConversationSummaryBufferMemory ì‚¬ìš©
   - ëŒ€í™”ê°€ ê¸¸ì–´ì§€ë©´ ìë™ìœ¼ë¡œ ìš”ì•½


ğŸ“š ì°¸ê³  ë¬¸ì„œ:
- ARCHITECTURE.md: ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ìƒì„¸ ì„¤ëª…
- IMPLEMENTATION_GUIDE.md: ë‹¨ê³„ë³„ êµ¬í˜„ ê°€ì´ë“œ
- README.md: í”„ë¡œì íŠ¸ ê°œìš”


âš ï¸ ì£¼ì˜ì‚¬í•­:
- ì´ íŒŒì¼ì˜ êµ¬ì¡°ëŠ” ê°€ì´ë“œì¼ ë¿ì…ë‹ˆë‹¤
- ììœ ë¡­ê²Œ ì¬ì„¤ê³„í•˜ê³  í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ë‹¨, generate_response() í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ëŠ” ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤
  (app.pyì—ì„œ í˜¸ì¶œí•˜ê¸° ë•Œë¬¸)
"""

import os
from pathlib import Path
from dotenv import load_dotenv
import json

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
BASE_DIR = Path(__file__).resolve().parent.parent


class ChatbotService:
    """
    ì±—ë´‡ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ” ì±—ë´‡ì˜ ëª¨ë“  AI ë¡œì§ì„ ìº¡ìŠí™”í•©ë‹ˆë‹¤.
    
    ì£¼ìš” ì±…ì„:
    1. OpenAI API ê´€ë¦¬
    2. ChromaDB ë²¡í„° ê²€ìƒ‰
    3. LangChain ë©”ëª¨ë¦¬ ê´€ë¦¬
    4. ì‘ë‹µ ìƒì„± íŒŒì´í”„ë¼ì¸
    
    í•™ìƒì´ êµ¬í˜„í•´ì•¼ í•  ë©”ì„œë“œ:
    - __init__: ëª¨ë“  êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”
    - _load_config: ì„¤ì • íŒŒì¼ ë¡œë“œ
    - _init_chromadb: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    - _create_embedding: í…ìŠ¤íŠ¸ â†’ ë²¡í„° ë³€í™˜
    - _search_similar: RAG ê²€ìƒ‰ ìˆ˜í–‰ (í•µì‹¬!)
    - _build_prompt: í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    - generate_response: ìµœì¢… ì‘ë‹µ ìƒì„± (ëª¨ë“  ë¡œì§ í†µí•©)
    """
    
    def __init__(self):
        """
        ì±—ë´‡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        
        TODO: ë‹¤ìŒ êµ¬ì„± ìš”ì†Œë“¤ì„ ì´ˆê¸°í™”í•˜ì„¸ìš”
        
        1. Config ë¡œë“œ
           - config/chatbot_config.json íŒŒì¼ ì½ê¸°
           - ì±—ë´‡ ì´ë¦„, ì„¤ëª…, ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë“±
        
        2. OpenAI Client
           - API í‚¤: os.getenv("OPENAI_API_KEY")
           - from openai import OpenAI
           - self.client = OpenAI(api_key=...)
        
        3. ChromaDB
           - í…ìŠ¤íŠ¸ ì„ë² ë”© ì»¬ë ‰ì…˜ ì—°ê²°
           - ê²½ë¡œ: static/data/chatbot/chardb_embedding
           - self.collection = ...
        
        4. LangChain Memory (ì„ íƒ)
           - ConversationSummaryBufferMemory
           - ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
           - self.memory = ...
        
        íŒíŠ¸:
        - ChromaDB: import chromadb
        - LangChain: from langchain.memory import ConversationSummaryBufferMemory
        """
        print("[ChatbotService] ì´ˆê¸°í™” ì¤‘...")
        
        # ì—¬ê¸°ì— ì´ˆê¸°í™” ì½”ë“œ ì‘ì„±
        self.config = {}
        self.client = None
        self.collection = None
        self.memory = None
        
        print("[ChatbotService] ì´ˆê¸°í™” ì™„ë£Œ")
    
    
    def _load_config(self):
        """
        ì„¤ì • íŒŒì¼ ë¡œë“œ
        
        TODO: config/chatbot_config.json ì½ì–´ì„œ ë°˜í™˜
        
        ë°˜í™˜ê°’ ì˜ˆì‹œ:
        {
            "name": "ê¹€ì„œê°•",
            "character": {...},
            "system_prompt": {...}
        }
        """
        pass
    
    
    def _init_chromadb(self):
        """
        ChromaDB ì´ˆê¸°í™” ë° ì»¬ë ‰ì…˜ ë°˜í™˜
        
        TODO: 
        1. PersistentClient ìƒì„±
        2. ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° (ì´ë¦„: "rag_collection")
        3. ì»¬ë ‰ì…˜ ë°˜í™˜
        
        íŒíŠ¸:
        - import chromadb
        - db_path = BASE_DIR / "static/data/chatbot/chardb_embedding"
        - client = chromadb.PersistentClient(path=str(db_path))
        - collection = client.get_collection(name="rag_collection")
        """
        pass
    
    
    def _create_embedding(self, text: str) -> list:
        """
        í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜
        
        Args:
            text (str): ì„ë² ë”©í•  í…ìŠ¤íŠ¸
        
        Returns:
            list: 3072ì°¨ì› ë²¡í„° (text-embedding-3-large ëª¨ë¸)
        
        TODO:
        1. OpenAI API í˜¸ì¶œ
        2. embeddings.create() ì‚¬ìš©
        3. ë²¡í„° ë°˜í™˜
        
        íŒíŠ¸:
        - response = self.client.embeddings.create(
        -     input=[text],
        -     model="text-embedding-3-large"
        - )
        - return response.data[0].embedding
        """
        pass
    
    
    def _search_similar(self, query: str, threshold: float = 0.45, top_k: int = 5):
        """
        RAG ê²€ìƒ‰: ìœ ì‚¬í•œ ë¬¸ì„œ ì°¾ê¸° (í•µì‹¬ ë©”ì„œë“œ!)
        
        Args:
            query (str): ê²€ìƒ‰ ì§ˆì˜
            threshold (float): ìœ ì‚¬ë„ ì„ê³„ê°’ (0.3-0.5 ê¶Œì¥)
            top_k (int): ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜
        
        Returns:
            tuple: (document, similarity, metadata) ë˜ëŠ” (None, None, None)
        
        TODO: RAG ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
        
        1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
           query_embedding = self._create_embedding(query)
        
        2. ChromaDB ê²€ìƒ‰
           results = self.collection.query(
               query_embeddings=[query_embedding],
               n_results=top_k,
               include=["documents", "distances", "metadatas"]
           )
        
        3. ìœ ì‚¬ë„ ê³„ì‚° ë° í•„í„°ë§
           for doc, dist, meta in zip(...):
               similarity = 1 / (1 + dist)  â† ìœ ì‚¬ë„ ê³µì‹!
               if similarity >= threshold:
                   ...
        
        4. ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ë°˜í™˜
           return (best_document, best_similarity, metadata)
        
        
        ğŸ’¡ í•µì‹¬ ê°œë…:
        
        - Distance vs Similarity
          Â· ChromaDBëŠ” "ê±°ë¦¬(distance)"ë¥¼ ë°˜í™˜ (ì‘ì„ìˆ˜ë¡ ìœ ì‚¬)
          Â· ìš°ë¦¬ëŠ” "ìœ ì‚¬ë„(similarity)"ë¡œ ë³€í™˜ (í´ìˆ˜ë¡ ìœ ì‚¬)
          Â· ë³€í™˜ ê³µì‹: similarity = 1 / (1 + distance)
        
        - Threshold
          Â· 0.3: ë§¤ìš° ëŠìŠ¨í•œ ë§¤ì¹­ (ê´€ë ¨ì„± ë‚®ì•„ë„ OK)
          Â· 0.45: ì ë‹¹í•œ ë§¤ì¹­ (ì¶”ì²œ!)
          Â· 0.7: ë§¤ìš° ì—„ê²©í•œ ë§¤ì¹­ (ì •í™•í•œ ë‹µë§Œ)
        
        - Top K
          Â· 5-10ê°œ ì •ë„ ê²€ìƒ‰
          Â· ê·¸ ì¤‘ threshold ë„˜ëŠ” ê²ƒë§Œ ì‚¬ìš©
        
        
        ğŸ› ë””ë²„ê¹… íŒ:
        - print()ë¡œ ê²€ìƒ‰ ê²°ê³¼ í™•ì¸
        - ìœ ì‚¬ë„ ê°’ í™•ì¸ (ë„ˆë¬´ ë‚®ìœ¼ë©´ threshold ì¡°ì •)
        - ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš© í™•ì¸
        """
        pass
    
    
    def _build_prompt(self, user_message: str, context: str = None, username: str = "ì‚¬ìš©ì"):
        """
        LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        
        Args:
            user_message (str): ì‚¬ìš©ì ë©”ì‹œì§€
            context (str): RAG ê²€ìƒ‰ ê²°ê³¼ (ì„ íƒ)
            username (str): ì‚¬ìš©ì ì´ë¦„
        
        Returns:
            str: ìµœì¢… í”„ë¡¬í”„íŠ¸
        
        TODO:
        1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸° (configì—ì„œ)
        2. RAG ì»¨í…ìŠ¤íŠ¸ í¬í•¨ ì—¬ë¶€ ê²°ì •
        3. ëŒ€í™” ê¸°ë¡ í¬í•¨ (ì„ íƒ)
        4. ìµœì¢… í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´ ë°˜í™˜
        
        í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ:
        ```
        ë‹¹ì‹ ì€ ì„œê°•ëŒ€í•™êµ ì„ ë°° ê¹€ì„œê°•ì…ë‹ˆë‹¤.
        ì‹ ì…ìƒë“¤ì—ê²Œ í•™êµ ìƒí™œì„ ì•Œë ¤ì£¼ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
        
        [ì°¸ê³  ì •ë³´]  â† RAG ì»¨í…ìŠ¤íŠ¸ê°€ ìˆì„ ë•Œë§Œ
        í•™ì‹ì€ ê³¤ìê°€ê°€ ë§›ìˆì–´. ëˆê¹ŒìŠ¤ê°€ ì¸ê¸°ì•¼.
        
        ì‚¬ìš©ì: í•™ì‹ ì¶”ì²œí•´ì¤˜
        ```
        """
        pass
    
    
    def generate_response(self, user_message: str, username: str = "ì‚¬ìš©ì") -> dict:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ ì±—ë´‡ ì‘ë‹µ ìƒì„±
        
        Args:
            user_message (str): ì‚¬ìš©ì ì…ë ¥
            username (str): ì‚¬ìš©ì ì´ë¦„
        
        Returns:
            dict: {
                'reply': str,       # ì±—ë´‡ ì‘ë‹µ í…ìŠ¤íŠ¸
                'image': str|None   # ì´ë¯¸ì§€ ê²½ë¡œ (ì„ íƒ)
            }
        
        
        TODO: ì „ì²´ ì‘ë‹µ ìƒì„± íŒŒì´í”„ë¼ì¸ êµ¬í˜„
        
        
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ğŸ“‹ êµ¬í˜„ ë‹¨ê³„
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        [1ë‹¨ê³„] ì´ˆê¸° ë©”ì‹œì§€ ì²˜ë¦¬
        
            if user_message.strip().lower() == "init":
                # ì²« ì¸ì‚¬ë§ ë°˜í™˜
                bot_name = self.config.get('name', 'ì±—ë´‡')
                return {
                    'reply': f"ì•ˆë…•! ë‚˜ëŠ” {bot_name}ì´ì•¼.",
                    'image': None
                }
        
        
        [2ë‹¨ê³„] RAG ê²€ìƒ‰ ìˆ˜í–‰
        
            context, similarity, metadata = self._search_similar(
                query=user_message,
                threshold=0.45,
                top_k=5
            )
            
            has_context = (context is not None)
        
        
        [3ë‹¨ê³„] í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        
            prompt = self._build_prompt(
                user_message=user_message,
                context=context,
                username=username
            )
        
        
        [4ë‹¨ê³„] LLM API í˜¸ì¶œ
        
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",  # ë˜ëŠ” gpt-4
                messages=[
                    {"role": "system", "content": "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            reply = response.choices[0].message.content
        
        
        [5ë‹¨ê³„] ë©”ëª¨ë¦¬ ì €ì¥ (ì„ íƒ)
        
            if self.memory:
                self.memory.save_context(
                    {"input": user_message},
                    {"output": reply}
                )
        
        
        [6ë‹¨ê³„] ì‘ë‹µ ë°˜í™˜
        
            return {
                'reply': reply,
                'image': None  # ì´ë¯¸ì§€ ê²€ìƒ‰ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
            }
        
        
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ğŸ’¡ í•µì‹¬ í¬ì¸íŠ¸
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        1. RAG í™œìš©
           - ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
           - ì—†ìœ¼ë©´ ì¼ë°˜ ëŒ€í™” ëª¨ë“œ
        
        2. ì—ëŸ¬ ì²˜ë¦¬
           - try-exceptë¡œ API ì˜¤ë¥˜ ì²˜ë¦¬
           - ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
        
        3. ë¡œê¹…
           - ê° ë‹¨ê³„ë§ˆë‹¤ print()ë¡œ ìƒíƒœ ì¶œë ¥
           - ë””ë²„ê¹…ì— ë§¤ìš° ìœ ìš©!
        
        4. í™•ì¥ì„±
           - ì´ë¯¸ì§€ ê²€ìƒ‰ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
           - ê°ì • ë¶„ì„ ì¶”ê°€ ê°€ëŠ¥
           - ë‹¤ì¤‘ ì–¸ì–´ ì§€ì› ê°€ëŠ¥
        
        
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ğŸ› ë””ë²„ê¹… ì˜ˆì‹œ
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        print(f"\n{'='*50}")
        print(f"[USER] {username}: {user_message}")
        print(f"[RAG] Context found: {has_context}")
        if has_context:
            print(f"[RAG] Similarity: {similarity:.4f}")
            print(f"[RAG] Context: {context[:100]}...")
        print(f"[LLM] Calling API...")
        print(f"[BOT] {reply}")
        print(f"{'='*50}\n")
        """
        
        # ì—¬ê¸°ì— ì „ì²´ íŒŒì´í”„ë¼ì¸ êµ¬í˜„
        # ìœ„ì˜ ë‹¨ê³„ë¥¼ ì°¸ê³ í•˜ì—¬ ììœ ë¡­ê²Œ ì„¤ê³„í•˜ì„¸ìš”
        
        try:
            # êµ¬í˜„ ì‹œì‘
            pass
            
        except Exception as e:
            print(f"[ERROR] ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'reply': "ì£„ì†¡í•´ìš”, ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                'image': None
            }


# ============================================================================
# ì‹±ê¸€í†¤ íŒ¨í„´
# ============================================================================
# ChatbotService ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì•± ì „ì²´ì—ì„œ ì¬ì‚¬ìš©
# (ë§¤ë²ˆ ìƒˆë¡œ ì´ˆê¸°í™”í•˜ë©´ ë¹„íš¨ìœ¨ì )

_chatbot_service = None

def get_chatbot_service():
    """
    ì±—ë´‡ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤)
    
    ì²« í˜¸ì¶œ ì‹œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±, ì´í›„ ì¬ì‚¬ìš©
    """
    global _chatbot_service
    if _chatbot_service is None:
        _chatbot_service = ChatbotService()
    return _chatbot_service


# ============================================================================
# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
# ============================================================================

if __name__ == "__main__":
    """
    ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©
    
    ì‹¤í–‰ ë°©ë²•:
    python services/chatbot_service.py
    """
    print("ì±—ë´‡ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    service = get_chatbot_service()
    
    # ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
    response = service.generate_response("init", "í…ŒìŠ¤í„°")
    print(f"ì´ˆê¸° ì‘ë‹µ: {response}")
    
    # ì¼ë°˜ ëŒ€í™” í…ŒìŠ¤íŠ¸
    response = service.generate_response("ì•ˆë…•í•˜ì„¸ìš”!", "í…ŒìŠ¤í„°")
    print(f"ì‘ë‹µ: {response}")
