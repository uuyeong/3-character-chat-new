# ğŸ”§ AI ë¡œì§ êµ¬í˜„ ê°€ì´ë“œ

> `services/chatbot_service.py` êµ¬í˜„ì„ ìœ„í•œ ì‹¤ì „ ê°€ì´ë“œ

---

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” `ChatbotService` í´ë˜ìŠ¤ì˜ í•µì‹¬ ë©”ì„œë“œë¥¼ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.

**íŒŒì¼ ìœ„ì¹˜**: `services/chatbot_service.py`  
**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 3-4ì‹œê°„  
**ë‚œì´ë„**: ì¤‘ê¸‰  
**ì „ì œ ì§€ì‹**: Python ê¸°ì´ˆ, API ì‚¬ìš© ê²½í—˜

---

## ğŸ¯ êµ¬í˜„ ìˆœì„œ

```
1. __init__         : ì´ˆê¸°í™” (30ë¶„)
   â†“
2. _load_config     : ì„¤ì • ë¡œë“œ (10ë¶„)
   â†“
3. _init_chromadb   : DB ì—°ê²° (20ë¶„)
   â†“
4. _create_embedding: ì„ë² ë”© ìƒì„± (15ë¶„)
   â†“
5. _search_similar  : RAG ê²€ìƒ‰ â­ (60ë¶„)
   â†“
6. _build_prompt    : í”„ë¡¬í”„íŠ¸ ì„¤ê³„ (30ë¶„)
   â†“
7. generate_response: ì „ì²´ í†µí•© â­â­ (60ë¶„)
```

---

## ğŸ“š ì‚¬ì „ í•™ìŠµ: í•µì‹¬ ê°œë…

### 1. Embedding (ì„ë² ë”©)

**ê°œë…**: í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜

```python
# Before
text = "í•™ì‹ ì¶”ì²œí•´ì¤˜"

# After (Embedding)
vector = [0.12, -0.34, 0.56, ..., 0.78]  # 3072ì°¨ì›
```

**ì™œ í•„ìš”í•œê°€?**
- ì»´í“¨í„°ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ë¹„êµ ëª»í•¨
- ë²¡í„°ë¡œ ë³€í™˜í•˜ë©´ ìˆ˜í•™ì  ìœ ì‚¬ë„ ê³„ì‚° ê°€ëŠ¥
- ì˜ë¯¸ê°€ ë¹„ìŠ·í•˜ë©´ ë²¡í„°ë„ ë¹„ìŠ·í•¨!

```python
"í•™ì‹ ì¶”ì²œ" â†’ [0.1, 0.3, ...]
"ë°¥ ì¶”ì²œ"   â†’ [0.11, 0.29, ...]  # ìœ ì‚¬í•¨!
"ë‚ ì”¨"      â†’ [-0.5, 0.8, ...]  # ë‹¤ë¦„!
```

### 2. RAG (Retrieval-Augmented Generation)

**ê°œë…**: ê²€ìƒ‰ + ìƒì„±

```
ì§ˆë¬¸: "í•™ì‹ ì¶”ì²œí•´ì¤˜"
  â†“
[1. ê²€ìƒ‰] ChromaDBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°
  "í•™ì‹ì€ ê³¤ìê°€ê°€ ë§›ìˆì–´"
  â†“
[2. ìƒì„±] LLMì—ê²Œ ê²€ìƒ‰ ê²°ê³¼ì™€ í•¨ê»˜ ì§ˆë¬¸
  LLM: "í•™ì‹ì€ ê³¤ìê°€ì—ì„œ ë¨¹ëŠ” ê²Œ ì¢‹ì•„!"
```

**ì™œ í•„ìš”í•œê°€?**
- LLMë§Œ ì“°ë©´: í™˜ê°(hallucination) ë°œìƒ
- RAG ì“°ë©´: ì •í™•í•œ ì •ë³´ ê¸°ë°˜ ë‹µë³€

### 3. ìœ ì‚¬ë„ ê³„ì‚°

**Distance â†’ Similarity ë³€í™˜**:

```python
# ChromaDBëŠ” ê±°ë¦¬(distance)ë¥¼ ë°˜í™˜
distance = 0.15  # ì‘ì„ìˆ˜ë¡ ìœ ì‚¬

# ìš°ë¦¬ëŠ” ìœ ì‚¬ë„(similarity)ë¡œ ë³€í™˜
similarity = 1 / (1 + distance)
# similarity = 1 / (1 + 0.15) = 0.87

# í•´ì„:
# similarity 0.9 ì´ìƒ: ê±°ì˜ ê°™ìŒ
# similarity 0.7-0.9: ë§¤ìš° ìœ ì‚¬
# similarity 0.5-0.7: ê´€ë ¨ ìˆìŒ
# similarity 0.5 ë¯¸ë§Œ: ë³„ë¡œ ê´€ë ¨ ì—†ìŒ
```

---

## ğŸ› ï¸ ë‹¨ê³„ë³„ êµ¬í˜„

### Step 1: ì´ˆê¸°í™” (__init__)

**ëª©í‘œ**: í•„ìš”í•œ ëª¨ë“  êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”

```python
def __init__(self):
    print("[ChatbotService] ì´ˆê¸°í™” ì¤‘...")
    
    # 1. Config ë¡œë“œ
    self.config = self._load_config()
    
    # 2. OpenAI Client
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    from openai import OpenAI
    self.client = OpenAI(api_key=api_key)
    
    # 3. ChromaDB
    self.collection = self._init_chromadb()
    
    # 4. LangChain Memory (ì„ íƒ)
    from langchain_community.chat_models import ChatOpenAI
    from langchain.memory import ConversationSummaryBufferMemory
    
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
    self.memory = ConversationSummaryBufferMemory(
        llm=llm,
        max_token_limit=500,
        return_messages=True
    )
    
    print("[ChatbotService] ì´ˆê¸°í™” ì™„ë£Œ")
```

**í•„ìš”í•œ import**:
```python
import os
from openai import OpenAI
import chromadb
from langchain_community.chat_models import ChatOpenAI
from langchain.memory import ConversationSummaryBufferMemory
```

---

### Step 2: ì„¤ì • ë¡œë“œ (_load_config)

**ëª©í‘œ**: JSON íŒŒì¼ì—ì„œ ì±—ë´‡ ì„¤ì • ì½ê¸°

```python
def _load_config(self):
    config_path = BASE_DIR / 'config' / 'chatbot_config.json'
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print("[WARNING] config íŒŒì¼ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©")
        return {
            'name': 'ì±—ë´‡',
            'system_prompt': {
                'base': 'ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì±—ë´‡ì…ë‹ˆë‹¤.',
                'rules': []
            }
        }
```

---

### Step 3: ChromaDB ì´ˆê¸°í™” (_init_chromadb)

**ëª©í‘œ**: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°

```python
def _init_chromadb(self):
    import chromadb
    
    # DB ê²½ë¡œ
    db_path = BASE_DIR / "static/data/chatbot/chardb_embedding"
    
    # ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ìœ¼ë©´)
    db_path.mkdir(parents=True, exist_ok=True)
    
    # Client ìƒì„±
    client = chromadb.PersistentClient(path=str(db_path))
    
    # Collection ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ìƒì„±)
    collection = client.get_or_create_collection(
        name="rag_collection",
        metadata={"description": "RAGë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ ì„ë² ë”©"}
    )
    
    print(f"[ChromaDB] ì»¬ë ‰ì…˜ ì—°ê²° ì™„ë£Œ (ë¬¸ì„œ ìˆ˜: {collection.count()})")
    
    return collection
```

**ì£¼ì˜**: ì²˜ìŒ ì‹¤í–‰ ì‹œ ì»¬ë ‰ì…˜ì´ ë¹„ì–´ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¨¼ì € ì„ë² ë”©í•´ì•¼ í•©ë‹ˆë‹¤!

---

### Step 4: ì„ë² ë”© ìƒì„± (_create_embedding)

**ëª©í‘œ**: í…ìŠ¤íŠ¸ â†’ ë²¡í„° ë³€í™˜

```python
def _create_embedding(self, text: str) -> list:
    try:
        response = self.client.embeddings.create(
            input=[text],
            model="text-embedding-3-large"
        )
        
        embedding = response.data[0].embedding
        
        print(f"[Embedding] ìƒì„± ì™„ë£Œ (ì°¨ì›: {len(embedding)})")
        
        return embedding
        
    except Exception as e:
        print(f"[ERROR] Embedding ìƒì„± ì‹¤íŒ¨: {e}")
        raise
```

**í…ŒìŠ¤íŠ¸**:
```python
embedding = chatbot._create_embedding("ì•ˆë…•í•˜ì„¸ìš”")
print(len(embedding))  # 3072
print(embedding[:5])   # [0.12, -0.34, ...]
```

---

### Step 5: RAG ê²€ìƒ‰ (_search_similar) â­ í•µì‹¬!

**ëª©í‘œ**: ìœ ì‚¬ ë¬¸ì„œ ì°¾ê¸°

```python
def _search_similar(self, query: str, threshold: float = 0.45, top_k: int = 5):
    print(f"\n[RAG] ê²€ìƒ‰ ì‹œì‘: '{query}'")
    
    try:
        # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = self._create_embedding(query)
        
        # 2. ChromaDB ê²€ìƒ‰
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            include=["documents", "distances", "metadatas"]
        )
        
        # 3. ê²°ê³¼ í™•ì¸
        if not results["documents"] or not results["documents"][0]:
            print("[RAG] ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            return None, None, None
        
        documents = results["documents"][0]
        distances = results["distances"][0]
        metadatas = results["metadatas"][0]
        
        # 4. ìœ ì‚¬ë„ ê³„ì‚° ë° í•„í„°ë§
        best_doc = None
        best_similarity = 0
        best_meta = None
        
        for doc, dist, meta in zip(documents, distances, metadatas):
            # ê±°ë¦¬ â†’ ìœ ì‚¬ë„ ë³€í™˜
            similarity = 1 / (1 + dist)
            
            print(f"[RAG] ë¬¸ì„œ: {doc[:50]}... | ìœ ì‚¬ë„: {similarity:.4f}")
            
            # Threshold ì²´í¬
            if similarity >= threshold and similarity > best_similarity:
                best_doc = doc
                best_similarity = similarity
                best_meta = meta
        
        # 5. ê²°ê³¼ ë°˜í™˜
        if best_doc:
            print(f"[RAG] âœ… ì„ íƒ: ìœ ì‚¬ë„ {best_similarity:.4f}")
            return best_doc, best_similarity, best_meta
        else:
            print(f"[RAG] âŒ Threshold({threshold}) ì´ìƒ ì—†ìŒ")
            return None, None, None
            
    except Exception as e:
        print(f"[ERROR] RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return None, None, None
```

**Threshold ì„ íƒ ê°€ì´ë“œ**:
- `0.3`: ë§¤ìš° ëŠìŠ¨ (ë§ì€ ê²°ê³¼)
- `0.45`: **ì¶”ì²œ** (ì ì ˆí•œ ê· í˜•)
- `0.6`: ì—„ê²© (ì •í™•í•œ ë§¤ì¹­ë§Œ)
- `0.8`: ë§¤ìš° ì—„ê²© (ê±°ì˜ ë™ì¼í•œ ê²ƒë§Œ)

---

### Step 6: í”„ë¡¬í”„íŠ¸ êµ¬ì„± (_build_prompt)

**ëª©í‘œ**: LLMì— ë³´ë‚¼ ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±

```python
def _build_prompt(self, user_message: str, context: str = None, username: str = "ì‚¬ìš©ì"):
    # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    system_prompt = self.config.get('system_prompt', {}).get('base', '')
    rules = self.config.get('system_prompt', {}).get('rules', [])
    
    prompt = system_prompt
    
    # 2. ê·œì¹™ ì¶”ê°€
    if rules:
        prompt += "\n\n[ëŒ€í™” ê·œì¹™]\n"
        for rule in rules:
            prompt += f"- {rule}\n"
    
    # 3. RAG ì»¨í…ìŠ¤íŠ¸ (ìˆìœ¼ë©´)
    if context:
        prompt += f"\n\n[ì°¸ê³  ì •ë³´]\n{context}\n"
    
    # 4. ì‚¬ìš©ì ë©”ì‹œì§€
    prompt += f"\n\n{username}: {user_message}\n"
    
    return prompt
```

**ì˜ˆì‹œ ì¶œë ¥**:
```
ë‹¹ì‹ ì€ ì„œê°•ëŒ€ ì„ ë°°ì…ë‹ˆë‹¤.
ì‹ ì…ìƒë“¤ì—ê²Œ í•™êµ ìƒí™œì„ ì•Œë ¤ì£¼ì„¸ìš”.

[ëŒ€í™” ê·œì¹™]
- ì¹œê·¼í•˜ê²Œ ë°˜ë§ë¡œ ëŒ€í™”í•˜ì„¸ìš”
- êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”

[ì°¸ê³  ì •ë³´]
í•™ì‹ì€ ê³¤ìê°€ê°€ ë§›ìˆì–´. ëˆê¹ŒìŠ¤ê°€ ì¸ê¸°ì•¼.

ì‚¬ìš©ì: í•™ì‹ ì¶”ì²œí•´ì¤˜
```

---

### Step 7: ì‘ë‹µ ìƒì„± (generate_response) â­â­ í†µí•©!

**ëª©í‘œ**: ëª¨ë“  ë‹¨ê³„ë¥¼ í†µí•©í•˜ì—¬ ìµœì¢… ì‘ë‹µ ìƒì„±

```python
def generate_response(self, user_message: str, username: str = "ì‚¬ìš©ì") -> dict:
    print(f"\n{'='*60}")
    print(f"[USER] {username}: {user_message}")
    
    try:
        # 1. ì´ˆê¸° ë©”ì‹œì§€ ì²˜ë¦¬
        if user_message.strip().lower() == "init":
            bot_name = self.config.get('name', 'ì±—ë´‡')
            greeting = f"ì•ˆë…•! ë‚˜ëŠ” {bot_name}ì´ì•¼. ë­ ê¶ê¸ˆí•œ ê±° ìˆì–´?"
            
            # ë©”ëª¨ë¦¬ ì €ì¥
            self.memory.save_context(
                {"input": ""},
                {"output": greeting}
            )
            
            return {'reply': greeting, 'image': None}
        
        # 2. RAG ê²€ìƒ‰
        context, similarity, metadata = self._search_similar(
            query=user_message,
            threshold=0.45,
            top_k=5
        )
        
        has_context = (context is not None)
        
        # 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self._build_prompt(
            user_message=user_message,
            context=context,
            username=username
        )
        
        # 4. LLM API í˜¸ì¶œ
        print(f"[LLM] API í˜¸ì¶œ ì¤‘...")
        
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": self.config.get('system_prompt', {}).get('base', '')},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )
        
        reply = response.choices[0].message.content
        
        print(f"[LLM] ì‘ë‹µ ì™„ë£Œ: {reply[:50]}...")
        
        # 5. ë©”ëª¨ë¦¬ ì €ì¥
        self.memory.save_context(
            {"input": user_message},
            {"output": reply}
        )
        
        # 6. ì‘ë‹µ ë°˜í™˜
        print(f"{'='*60}\n")
        
        return {
            'reply': reply,
            'image': None  # TODO: ì´ë¯¸ì§€ ê²€ìƒ‰ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
        }
        
    except Exception as e:
        print(f"[ERROR] ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        
        return {
            'reply': "ì£„ì†¡í•´ìš”, ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            'image': None
        }
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë°©ë²•

### 1. ë¡œì»¬ í…ŒìŠ¤íŠ¸

```bash
# íŒŒì¼ ì§ì ‘ ì‹¤í–‰
python services/chatbot_service.py
```

### 2. Docker í…ŒìŠ¤íŠ¸

```bash
docker-compose up
# http://localhost:5001 ì ‘ì†
```

### 3. ë””ë²„ê¹… ë¡œê·¸ í™•ì¸

```python
# chatbot_service.pyì—ì„œ ë¡œê·¸ ì¶”ê°€
print(f"[DEBUG] Embedding: {embedding[:3]}...")
print(f"[DEBUG] Similarity: {similarity:.4f}")
print(f"[DEBUG] Context: {context}")
```

---

## ğŸ’¡ í™•ì¥ ì•„ì´ë””ì–´

### 1. ì´ë¯¸ì§€ ê²€ìƒ‰ ì¶”ê°€

```python
def _search_similar_image(self, query: str):
    # ì´ë¯¸ì§€ ì„ë² ë”© DBì—ì„œ ê²€ìƒ‰
    # ìœ ì‚¬í•œ ì´ë¯¸ì§€ ê²½ë¡œ ë°˜í™˜
    pass
```

### 2. í•œêµ­ì–´ í‚¤ì›Œë“œ ì¶”ì¶œ

```python
def _extract_keywords(self, text: str):
    from konlpy.tag import Okt
    okt = Okt()
    nouns = okt.nouns(text)
    return nouns
```

### 3. ê°ì • ë¶„ì„

```python
def _analyze_emotion(self, text: str):
    # ì‚¬ìš©ì ê°ì • íŒŒì•…
    # ê°ì •ì— ë§ëŠ” ì‘ë‹µ ìƒì„±
    pass
```

---

## ğŸ› ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜

### 1. "OPENAI_API_KEY not found"

**ì›ì¸**: `.env` íŒŒì¼ì´ ì—†ê±°ë‚˜ API í‚¤ê°€ ì—†ìŒ  
**í•´ê²°**:
```bash
cp .env.example .env
# .env íŒŒì¼ì— API í‚¤ ì…ë ¥
```

### 2. "Collection not found"

**ì›ì¸**: ChromaDBì— ë°ì´í„°ê°€ ì—†ìŒ  
**í•´ê²°**: í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¨¼ì € ì„ë² ë”©í•´ì•¼ í•¨ (ë³„ë„ ìŠ¤í¬ë¦½íŠ¸ í•„ìš”)

### 3. "Rate limit exceeded"

**ì›ì¸**: OpenAI API í˜¸ì¶œ ì œí•œ ì´ˆê³¼  
**í•´ê²°**: 
- API í‚¤ í™•ì¸
- ìš”ì²­ ì†ë„ ì¤„ì´ê¸°
- ìƒìœ„ í”Œëœ êµ¬ë§¤

---

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### 1. Embedding ìºì‹±

```python
# ë™ì¼í•œ ì¿¼ë¦¬ëŠ” ìºì‹±
self.embedding_cache = {}

def _create_embedding(self, text: str):
    if text in self.embedding_cache:
        return self.embedding_cache[text]
    
    embedding = ...  # OpenAI API í˜¸ì¶œ
    self.embedding_cache[text] = embedding
    return embedding
```

### 2. Batch Processing

```python
# ì—¬ëŸ¬ í…ìŠ¤íŠ¸ í•œ ë²ˆì— ì„ë² ë”©
texts = ["ì•ˆë…•", "í•™ì‹", "ë„ì„œê´€"]
embeddings = self.client.embeddings.create(
    input=texts,
    model="text-embedding-3-large"
)
```

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

1. âœ… `chatbot_service.py` êµ¬í˜„ ì™„ë£Œ
2. í…ìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ë° ì„ë² ë”©
3. Dockerë¡œ í…ŒìŠ¤íŠ¸
4. Vercel ë°°í¬

**ì°¸ê³  ë¬¸ì„œ**:
- [ARCHITECTURE.md](ARCHITECTURE.md) - ì‹œìŠ¤í…œ êµ¬ì¡°
- [ASSIGNMENT_GUIDE.md](ASSIGNMENT_GUIDE.md) - ì „ì²´ ì›Œí¬í”Œë¡œìš°
- [DOCKER_GUIDE.md](DOCKER_GUIDE.md) - Docker ì‚¬ìš©ë²•